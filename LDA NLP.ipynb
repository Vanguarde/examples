{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T08:03:30.913919Z",
     "start_time": "2021-01-19T08:02:43.133597Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from nltk import word_tokenize, ngrams\n",
    "from tqdm.notebook import tqdm\n",
    "import artm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaMulticore\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import csv\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T08:03:30.947502Z",
     "start_time": "2021-01-19T08:03:30.915585Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b,\n",
    "                                           per_word_topics=True)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "def remove_stopwords(text, check_status=True):\n",
    "    stop_list = stopwords.words('russian')\n",
    "    stop_list_2 = [...]\n",
    "    with open('RussianStopWords.txt', encoding='utf-8') as stops:\n",
    "        heh = stops.read()\n",
    "        stop_list_3 = heh.split('\\n')\n",
    "    stops.close()\n",
    "    set_stop = set(stop_list)\n",
    "    set_stop.update(stop_list_2)\n",
    "    set_stop.update(stop_list_3)\n",
    "    set_stop.update([...])\n",
    "    locs = pd.read_csv('locs.csv', header=None)\n",
    "    city_list = list(locs[2])\n",
    "    set_stop.update(city_list)\n",
    "    prilag_stops = [...]\n",
    "    \n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    words = []\n",
    "    if check_status:\n",
    "        txt_news = tqdm(text)\n",
    "    else:\n",
    "        txt_news = text\n",
    "    for news_proc in txt_news:\n",
    "        news_proc = word_tokenize(news_proc[0])\n",
    "        words_lem = []\n",
    "        for word in news_proc:\n",
    "            p = morph.parse(word)\n",
    "            lem = word\n",
    "            #убираем мусор из стоп-листа и имена с фамилиями\n",
    "            if word not in set_stop and not ('Surn' in p[0].tag or 'Name' in p[0].tag) and len(lem) > 3:\n",
    "                if not any(prilag in lem for prilag in prilag_stops):\n",
    "                    words_lem.append(lem)\n",
    "        words.append(words_lem)\n",
    "    return words\n",
    "\n",
    "def make_bigrams(texts, save=False):\n",
    "    bigram = gensim.models.Phrases(texts, min_count=5, threshold=50)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    if save:\n",
    "        bigram.save('model/grams/bigrams.phs')\n",
    "        try:\n",
    "            bigram.save('model/grams/bigrams.pkl')\n",
    "        except:\n",
    "            pass\n",
    "    print('создаем биграммы')\n",
    "    return [bigram_mod[doc] for doc in tqdm(texts)]\n",
    "\n",
    "def make_trigrams(texts, save=False):\n",
    "    trigram = gensim.models.Phrases(texts, min_count=5, threshold=50)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    if save:\n",
    "        trigram.save('model/grams/trigrams.phs')\n",
    "        try:\n",
    "            trigram.save('model/grams/trigrams.pkl')\n",
    "        except:\n",
    "            pass\n",
    "    print('создаем триграммы')\n",
    "    return [trigram_mod[doc] for doc in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-18T06:30:06.457Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(text, min_count=5, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram.save('model/grams/bigrams.phs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T10:08:22.982266Z",
     "start_time": "2021-01-17T09:54:09.438367Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('model/text_ready_full/text_full.txt', 'w') as tx:\n",
    "    writer = csv.writer(tx)\n",
    "    writer.writerows(text)\n",
    "    tx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T14:07:39.840840Z",
     "start_time": "2021-01-15T14:02:56.467775Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///....db', echo=False)\n",
    "sqlite_connection = engine.connect()\n",
    "text = sqlite_connection.execute(\"SELECT stemmed FROM news_db\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T18:47:33.837871Z",
     "start_time": "2021-01-15T14:12:32.143569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33c3e1e429d44368e48717f5a3db5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=691191.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T04:09:28.570298Z",
     "start_time": "2021-01-15T18:47:34.611710Z"
    }
   },
   "outputs": [],
   "source": [
    "print('биграммы')\n",
    "text_grams = make_bigrams(text, save=True)\n",
    "text_grams = make_trigrams(text_grams, save=True)\n",
    "id2word = corpora.Dictionary(text_grams)\n",
    "\n",
    "id2word.filter_extremes(no_below=20, no_above=0.7)\n",
    "\n",
    "corpus = [id2word.doc2bow(txt) for txt in text_grams]\n",
    "print('сохранение')\n",
    "pickle.dump(corpus, open('model/corpus_full.pkl', 'wb'))\n",
    "id2word.save('model/dictionary_full.gensim')\n",
    "print('модель')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T19:09:36.659396Z",
     "start_time": "2021-01-16T08:52:18.506310Z"
    }
   },
   "outputs": [],
   "source": [
    "coh_score = []\n",
    "for i in tqdm(range(5, 25)):\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                         id2word=id2word,\n",
    "                         num_topics=i,\n",
    "                         chunksize=1000,\n",
    "                         passes=5,\n",
    "                         random_state=100,\n",
    "                         alpha='symmetric',\n",
    "                         per_word_topics=True)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=text_grams, dictionary=id2word, coherence='c_v')\n",
    "    coh_score.append(coherence_model_lda.get_coherence())\n",
    "fig = plt.figure(figsize = [15,10])\n",
    "ax_1 = fig.add_subplot(1, 1, 1)\n",
    "ax_1.set_title('Когерентность в зависимости от количества тем')\n",
    "ax_1.set_xlabel('количество тем')\n",
    "ax_1.set_ylabel('Coherence')\n",
    "ax_1.plot(range(5, 25), coh_score, linestyle='dashed', label = 'Когерентность')\n",
    "ax_1.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T08:05:03.594357Z",
     "start_time": "2021-01-19T08:03:47.419600Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = pickle.load(open('model/corpus_full.pkl', 'rb'))\n",
    "id2word = corpora.Dictionary.load(f'model/dictionary_full.gensim')\n",
    "with open('model/text_ready_full/text_full.txt', 'r', encoding='utf-8') as text_train:\n",
    "    text_train = text_train.readlines()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
